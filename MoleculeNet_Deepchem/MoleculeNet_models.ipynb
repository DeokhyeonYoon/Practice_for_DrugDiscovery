{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict binding affinity from a protein-ligand crystal structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages installed in my conda environment: Deepchem, rdkit, pytorch, pytorch-geometric, tensorflow, pdbfixer, numpy <1.25\n",
    "# Deep Learning for the Life Sciences by Bharath Ramsundar, Peter Eastman, Patrick Walters and Vijay Pande\n",
    "# pdbbind dataset: Cheng, T.J. et al. J. Chem. Inf. Model., 2009, 49, 1079-1093. (PDBbind v.2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement transformaers (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for transformaers\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting tokenizers\n",
      "  Downloading tokenizers-0.15.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface_hub<1.0,>=0.16.4\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.42.1 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (22.0)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.4.0)\n",
      "Requirement already satisfied: requests in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.28.1)\n",
      "Requirement already satisfied: filelock in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.9.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from importlib-metadata->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.11.17)\n",
      "Installing collected packages: fsspec, huggingface_hub, tokenizers\n",
      "Successfully installed fsspec-2023.1.0 huggingface_hub-0.16.4 tokenizers-0.15.0\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting smart-open>=1.8.1\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from gensim) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from gensim) (1.21.5)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.2.0 smart-open-6.4.0\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement matminery (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for matminery\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting pyGPGO\n",
      "  Downloading pyGPGO-0.5.1.tar.gz (14 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from pyGPGO) (1.21.5)\n",
      "Collecting mkl\n",
      "  Downloading mkl-2024.0.0-py2.py3-none-manylinux1_x86_64.whl (200.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.7/200.7 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from pyGPGO) (1.7.3)\n",
      "Requirement already satisfied: joblib in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from pyGPGO) (1.1.1)\n",
      "Requirement already satisfied: scikit-learn in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from pyGPGO) (1.0.2)\n",
      "Collecting Theano-PyMC\n",
      "  Downloading Theano-PyMC-1.1.2.tar.gz (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyMC3\n",
      "  Downloading pymc3-3.11.5-py3-none-any.whl (872 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m872.2/872.2 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tbb==2021.*\n",
      "  Downloading tbb-2021.11.0-py2.py3-none-manylinux1_x86_64.whl (5.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting intel-openmp==2024.*\n",
      "  Downloading intel_openmp-2024.0.2-py2.py3-none-manylinux1_x86_64.whl (28.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.6/28.6 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting dill\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cachetools>=4.2.1 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from pyMC3->pyGPGO) (4.2.2)\n",
      "Collecting deprecat\n",
      "  Downloading deprecat-2.1.1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting semver>=2.13.0\n",
      "  Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
      "Collecting fastprogress>=0.2.0\n",
      "  Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from pyMC3->pyGPGO) (1.3.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from pyMC3->pyGPGO) (4.4.0)\n",
      "Collecting patsy>=0.5.1\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.9/233.9 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting arviz>=0.11.0\n",
      "  Downloading arviz-0.12.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from Theano-PyMC->pyGPGO) (3.9.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from scikit-learn->pyGPGO) (2.2.0)\n",
      "Collecting xarray>=0.16.1\n",
      "  Downloading xarray-0.20.2-py3-none-any.whl (845 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m845.2/845.2 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.0 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (3.5.3)\n",
      "Requirement already satisfied: packaging in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (22.0)\n",
      "Requirement already satisfied: setuptools>=38.4 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (65.6.3)\n",
      "Requirement already satisfied: netcdf4 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (1.6.2)\n",
      "Collecting xarray-einstats>=0.2\n",
      "  Downloading xarray_einstats-0.2.2-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from pandas>=0.24.0->pyMC3->pyGPGO) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from pandas>=0.24.0->pyMC3->pyGPGO) (2022.7)\n",
      "Requirement already satisfied: six in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from patsy>=0.5.1->pyMC3->pyGPGO) (1.16.0)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Downloading wrapt-1.16.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (9.4.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (4.11.3)\n",
      "Requirement already satisfied: cftime in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from netcdf4->arviz>=0.11.0->pyMC3->pyGPGO) (1.5.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from importlib-metadata->xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (3.11.0)\n",
      "Building wheels for collected packages: pyGPGO, Theano-PyMC\n",
      "  Building wheel for pyGPGO (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyGPGO: filename=pyGPGO-0.5.1-py3-none-any.whl size=19862 sha256=1d6741c4515862644089ebbe1f805c7690842e21108e6e542aa34435787e9d57\n",
      "  Stored in directory: /home/dbsejrgus226/.cache/pip/wheels/91/a9/7a/71f0635270b1a6dfb092d957e9e56eed6a8550116fa3027002\n",
      "  Building wheel for Theano-PyMC (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Theano-PyMC: filename=Theano_PyMC-1.1.2-py3-none-any.whl size=1529962 sha256=1f6edb214a42e601ee316742bed7efad2c5d5ca17eeb6f00298f48ff179530c6\n",
      "  Stored in directory: /home/dbsejrgus226/.cache/pip/wheels/ca/26/ff/1bccbd2d06d0ff14db22634e639715c0d7aadbc0c340060202\n",
      "Successfully built pyGPGO Theano-PyMC\n",
      "Installing collected packages: tbb, intel-openmp, wrapt, semver, patsy, mkl, fastprogress, dill, Theano-PyMC, deprecat, xarray, xarray-einstats, arviz, pyMC3, pyGPGO\n",
      "Successfully installed Theano-PyMC-1.1.2 arviz-0.12.1 deprecat-2.1.1 dill-0.3.7 fastprogress-1.0.3 intel-openmp-2024.0.2 mkl-2024.0.0 patsy-0.5.6 pyGPGO-0.5.1 pyMC3-3.11.5 semver-3.0.2 tbb-2021.11.0 wrapt-1.16.0 xarray-0.20.2 xarray-einstats-0.2.2\n"
     ]
    }
   ],
   "source": [
    "! pip install tokenizers\n",
    "! pip install gensim\n",
    "! pip install matminery\n",
    "! pip install pyGPGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: filelock in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from transformers) (4.11.3)\n",
      "Requirement already satisfied: requests in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from transformers) (4.64.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from transformers) (1.21.5)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.12.25-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (761 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m761.6/761.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.4.0)\n",
      "Requirement already satisfied: fsspec in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from requests->transformers) (2023.11.17)\n",
      "Installing collected packages: tokenizers, safetensors, regex, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.0\n",
      "    Uninstalling tokenizers-0.15.0:\n",
      "      Successfully uninstalled tokenizers-0.15.0\n",
      "Successfully installed regex-2023.12.25 safetensors-0.4.1 tokenizers-0.13.3 transformers-4.30.2\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement hsuite (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for hsuite\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: vina in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (1.2.5)\n",
      "Requirement already satisfied: numpy>=1.18 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from vina) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "! pip install hsuite\n",
    "! pip install vina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to install Libraries in yml file\n",
    "1.\n",
    " - 일반적으로 yml/yaml file에 있는 라이브러리들은 `requirements.txt` 파일 형식으로 작성되어 있다.\n",
    " - `pip` 는 이 파일을 읽어 필요한 라이브러리를 한번에 설치할 수 있다.\n",
    "\n",
    "\n",
    " - `pip install -r requirements.txt` 이 명령은 `requirements.txt` 파일에 있는 각 라이브러리와 해당 버전을 자동으로 가져와 설치한다.\n",
    " * `requirements.txt` 파일이 있는 디렉토리로 이동한 후 명령을 실행해야 한다.\n",
    "2. yml/yaml 파일을 사용하여 conda 환경 생성\n",
    " - `conda env create --file file_name.yaml`\n",
    " - `conda activate env_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "import openmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36093/1017616797.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m featurizer = dc.feat.RdkitGridFeaturizer(voxel_width=2.0,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                          \u001b[0mfeature_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ecfp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"splif\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"salt_bridge\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hbond\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                          \u001b[0mflatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                          sanitize = True)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dc' is not defined"
     ]
    }
   ],
   "source": [
    "featurizer = dc.feat.RdkitGridFeaturizer(voxel_width=2.0,\n",
    "                                         feature_types=[\"ecfp\", \"splif\", \"salt_bridge\", \"hbond\"],\n",
    "                                         flatten = True,\n",
    "                                         sanitize = True)\n",
    "\n",
    "# voxel_width : size of a 3D voxel in a grid(float, default 1.0)\n",
    "\n",
    "# feature_types\n",
    "# 1) Types of features to calculate. Available types are\n",
    "# flat features -> \"ecfp_ligand\", \"ecfp_hashed\", \"splif_hasged\", \"hbond_count\"\n",
    "# voxel features -> \"ecfp\", \"splif\", \"sybyl\", \"slat_bridge\", \"charge\", \"hbond\", \"pi_stack\", \"cation_pi\"\n",
    "# 2) There are also 3 predefined sets of features\n",
    "# \"flat_combined\", \"voxel_combined\", \"all_combined\"\n",
    "\n",
    "# flatten : indicate whether calculated features shcould be falttened.Output is always flattened if flat features are specified in feature_types.(bool, defaul True)\n",
    "# sanitize : if set to True molecules will be sanitized. Note that calculating some features require sanitized molecules(bool, defaul False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks, datasets, transformers = dc.molnet.load_pdbbind(featurizer=featurizer, reload=False, set_name = \"core\", data_dir=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-logKd/Ki']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<deepchem.trans.transformers.NormalizationTransformer at 0x7fc9250ed550>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, vaild, test = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int8\n",
      "float64\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(train.X.dtype)\n",
    "print(train.y.dtype)\n",
    "print(train.w.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.X.astype(\"float32\")\n",
    "y_train = train.y.astype(\"float32\")\n",
    "w_train = train.w.astype(\"float32\")\n",
    "\n",
    "x_test = test.X.astype(\"float32\")\n",
    "y_test = test.y.astype(\"float32\")\n",
    "w_test = test.w.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 18432)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dc.data.NumpyDataset(x_train, y_train, w_train)\n",
    "test_dataset = dc.data.NumpyDataset(x_test, y_test, w_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 18432)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultitaskRegressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.fcnet import MultitaskRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultitaskRegressor(n_tasks=1, n_features=train_dataset.X.shape[1], layer_sizes=[5000, 2000, 1000], dropouts=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07894916534423828"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, nb_epoch=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pearson_r2_score': 0.9941699984987219}\n"
     ]
    }
   ],
   "source": [
    "train_score = model.evaluate(train_dataset, [metric], transformers)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pearson_r2_score': 0.3525638779529341}\n"
     ]
    }
   ],
   "source": [
    "test_score = model.evaluate(test_dataset, [metric], transformers)\n",
    "print(test_score)#because there are a few data in test_dataset (20 ea)..., pearson R2 score is too bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 18432)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.9396967 ]],\n",
       "\n",
       "       [[ 0.44619823]],\n",
       "\n",
       "       [[-0.14021999]],\n",
       "\n",
       "       [[-0.536299  ]],\n",
       "\n",
       "       [[ 0.31962058]]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict_on_batch(test_dataset.X)\n",
    "prediction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.090814  , 0.69991004, 0.77123845, 0.00445803, 0.04458026],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1, 1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = prediction.reshape(20)\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'prediction')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax = sns.scatterplot(x=test_dataset.y, y=prediction)\n",
    "ax.set_title('pdbbind dataset')\n",
    "ax.set_xlabel('True')\n",
    "ax.set_ylabel('prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DiskDataset X.shape: (154, 18432), y.shape: (154,), w.shape: (154,), ids: ['3gy4' '3f3e' '1sqa' ... '1n2v' '3su5' '1qi0'], task_names: [0]>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DiskDataset X.shape: (20, 18432), y.shape: (20,), w.shape: (20,), ids: ['3utu' '1u1b' '2x8z' ... '3b3s' '2wbg' '3fv1'], task_names: [0]>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.X\n",
    "train_Y = train.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RFR = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_RFR.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test.X\n",
    "test_Y = test.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model_RFR.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson R^2 Score: 0.11874715367846189\n"
     ]
    }
   ],
   "source": [
    "r2_value = r2_score(test_Y, pred)\n",
    "print(f\"pearson R^2 Score: {r2_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Tensor Neural Networks\n",
    "### DTNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models import DTNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method DTNNStep.call of <deepchem.models.layers.DTNNStep object at 0x7fc922b1ac10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method DTNNStep.call of <deepchem.models.layers.DTNNStep object at 0x7fc922b1ac10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method DTNNGather.call of <deepchem.models.layers.DTNNGather object at 0x7fc9205474d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method DTNNGather.call of <deepchem.models.layers.DTNNGather object at 0x7fc9205474d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 15:29:43.354396: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-01-17 15:29:43.354640: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-17 15:29:43.355839: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model_DTNN = DTNNModel(n_tasks=1, n_embedding=20, n_distance=100, learning_rate=1.0, mode=\"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_132000/819423715.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_DTNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, nb_epoch, max_checkpoints_to_keep, checkpoint_interval, deterministic, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    354\u001b[0m                                deterministic=deterministic),\n\u001b[1;32m    355\u001b[0m         \u001b[0mmax_checkpoints_to_keep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         callbacks, all_losses)\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m   def fit_generator(self,\n",
      "\u001b[0;32m~/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;31m# Main training loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_training_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/models/graph_models.py\u001b[0m in \u001b[0;36mdefault_generator\u001b[0;34m(self, dataset, epochs, mode, deterministic, pad_batches)\u001b[0m\n\u001b[1;32m    563\u001b[0m                                          \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                                          pad_batches=pad_batches):\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_features_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/models/graph_models.py\u001b[0m in \u001b[0;36mcompute_features_on_batch\u001b[0;34m(self, X_b)\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0mdistance_membership_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0mdistance_membership_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m     \u001b[0mnum_atoms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m     atom_number = [\n\u001b[1;32m    523\u001b[0m         np.round(\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "model_DTNN.fit(train_dataset, nb_epoch=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bypass Network\n",
    "### RobustMultitaskRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models import RobustMultitaskRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RMR = RobustMultitaskRegressor(len(tasks), n_features=train_dataset.X.shape[1], batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function KerasModel._create_gradient_fn.<locals>.apply_gradient_for_batch at 0x7fc92044e710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function KerasModel._create_gradient_fn.<locals>.apply_gradient_for_batch at 0x7fc92044e710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 15:56:35.604257: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-01-17 15:56:35.623857: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3398140000 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04573721408843994"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RMR.fit(train_dataset, nb_epoch=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_RMR = dc.metrics.Metric(dc.metrics.pearson_r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pearson_r2_score': 0.9934782257865107}\n"
     ]
    }
   ],
   "source": [
    "train_score_RMR = model_RMR.evaluate(train_dataset, [metric_RMR], transformers)\n",
    "print(train_score_RMR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pearson_r2_score': 0.09280445424309997}\n"
     ]
    }
   ],
   "source": [
    "test_score_RMR = model_RMR.evaluate(test_dataset, [metric_RMR], transformers)\n",
    "print(test_score_RMR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Convolutional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models import GraphConvModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GCM= GraphConvModel(len(tasks),\n",
    "                          mode=\"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'atom_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_132000/1111744694.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_GCM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, nb_epoch, max_checkpoints_to_keep, checkpoint_interval, deterministic, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    354\u001b[0m                                deterministic=deterministic),\n\u001b[1;32m    355\u001b[0m         \u001b[0mmax_checkpoints_to_keep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         callbacks, all_losses)\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m   def fit_generator(self,\n",
      "\u001b[0;32m~/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;31m# Main training loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_training_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/models/graph_models.py\u001b[0m in \u001b[0;36mdefault_generator\u001b[0;34m(self, dataset, epochs, mode, deterministic, pad_batches)\u001b[0m\n\u001b[1;32m   1013\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_tasks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m                                                    self.n_classes)\n\u001b[0;32m-> 1015\u001b[0;31m         \u001b[0mmultiConvMol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvMol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magglomerate_mols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m         inputs = [\n",
      "\u001b[0;32m~/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/feat/mol_graphs.py\u001b[0m in \u001b[0;36magglomerate_mols\u001b[0;34m(mols, max_deg, min_deg)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# Combine the features, then sort them by (atom_degree, mol_index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0matoms_by_deg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matom_features\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0mdegree_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree_list\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;31m# Mergesort is a \"stable\" sort, so the array maintains it's secondary sort of mol_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/feat/mol_graphs.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# Combine the features, then sort them by (atom_degree, mol_index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0matoms_by_deg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matom_features\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0mdegree_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree_list\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;31m# Mergesort is a \"stable\" sort, so the array maintains it's secondary sort of mol_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'atom_features'"
     ]
    }
   ],
   "source": [
    "model_GCM.fit(train_dataset, nb_epoch=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Acyclic Graph Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models import DAGModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method DAGLayer.call of <deepchem.models.layers.DAGLayer object at 0x7fc92514c990>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method DAGLayer.call of <deepchem.models.layers.DAGLayer object at 0x7fc92514c990>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method DAGGather.call of <deepchem.models.layers.DAGGather object at 0x7fc9204bc610>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method DAGGather.call of <deepchem.models.layers.DAGGather object at 0x7fc9204bc610>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "model_DAG = DAGModel(n_tasks=1, n_atom_feat=train_dataset.X.shape[0], n_outputs=30, random_seed=123, use_queue=False, mode=\"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'get_num_atoms'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_132000/721136040.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_DAG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, nb_epoch, max_checkpoints_to_keep, checkpoint_interval, deterministic, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    354\u001b[0m                                deterministic=deterministic),\n\u001b[1;32m    355\u001b[0m         \u001b[0mmax_checkpoints_to_keep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         callbacks, all_losses)\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m   def fit_generator(self,\n",
      "\u001b[0;32m~/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;31m# Main training loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_training_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/models/graph_models.py\u001b[0m in \u001b[0;36mdefault_generator\u001b[0;34m(self, dataset, epochs, mode, deterministic, pad_batches)\u001b[0m\n\u001b[1;32m    744\u001b[0m                                                    self.n_classes)\n\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m         \u001b[0matoms_per_mol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_atoms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m         \u001b[0mn_atoms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matoms_per_mol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0mstart_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matoms_per_mol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/models/graph_models.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    744\u001b[0m                                                    self.n_classes)\n\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m         \u001b[0matoms_per_mol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_atoms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m         \u001b[0mn_atoms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matoms_per_mol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0mstart_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matoms_per_mol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'get_num_atoms'"
     ]
    }
   ],
   "source": [
    "model_DAG.fit(train_dataset, nb_epoch=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weave Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models import WeaveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method WeaveLayer.call of <deepchem.models.layers.WeaveLayer object at 0x7fc9256d8cd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method WeaveLayer.call of <deepchem.models.layers.WeaveLayer object at 0x7fc9256d8cd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "This class requires tensorflow-probability to be installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/models/layers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_size, n_input, gaussian_expand, compress_post_gaussian_expansion, init, activation, **kwargs)\u001b[0m\n\u001b[1;32m   3017\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3018\u001b[0;31m       \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_probability\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3019\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_probability'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_132000/1302659845.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_WM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWeaveModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_tasks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_queue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"regression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/models/graph_models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_tasks, n_atom_feat, n_pair_feat, n_hidden, n_graph_feat, n_weave, fully_connected_layer_sizes, conv_weight_init_stddevs, weight_init_stddevs, bias_init_consts, weight_decay_penalty, weight_decay_penalty_type, dropouts, final_conv_activation_fn, activation_fns, batch_normalize, batch_normalize_kwargs, gaussian_expand, compress_post_gaussian_expansion, mode, n_classes, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mn_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_graph_feat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mgaussian_expand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgaussian_expand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mcompress_post_gaussian_expansion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompress_post_gaussian_expansion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m             [dense1, atom_split])\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/models/layers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_size, n_input, gaussian_expand, compress_post_gaussian_expansion, init, activation, **kwargs)\u001b[0m\n\u001b[1;32m   3019\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3020\u001b[0m       raise ImportError(\n\u001b[0;32m-> 3021\u001b[0;31m           \"This class requires tensorflow-probability to be installed.\")\n\u001b[0m\u001b[1;32m   3022\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWeaveGather\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: This class requires tensorflow-probability to be installed."
     ]
    }
   ],
   "source": [
    "model_WM = WeaveModel(n_tasks=1, n_hidden=50, use_queue=False, random_seed=123, mode=\"regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message passing Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models import MPNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method MessagePassing.call of <deepchem.models.layers.MessagePassing object at 0x7fc8be580290>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method MessagePassing.call of <deepchem.models.layers.MessagePassing object at 0x7fc8be580290>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method EdgeNetwork.call of <deepchem.models.layers.EdgeNetwork object at 0x7fc8be658110>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method EdgeNetwork.call of <deepchem.models.layers.EdgeNetwork object at 0x7fc8be658110>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GatedRecurrentUnit.call of <deepchem.models.layers.GatedRecurrentUnit object at 0x7fc95246b090>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method GatedRecurrentUnit.call of <deepchem.models.layers.GatedRecurrentUnit object at 0x7fc95246b090>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method SetGather.call of <deepchem.models.layers.SetGather object at 0x7fc92570ee10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method SetGather.call of <deepchem.models.layers.SetGather object at 0x7fc92570ee10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TrimGraphOutput.call of <deepchem.models.graph_models.TrimGraphOutput object at 0x7fc8bea42f90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TrimGraphOutput.call of <deepchem.models.graph_models.TrimGraphOutput object at 0x7fc8bea42f90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "model_MPNN = MPNNModel(n_tasks=1, use_queue=False, mode=\"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'get_num_atoms'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_132000/2026538413.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_MPNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, nb_epoch, max_checkpoints_to_keep, checkpoint_interval, deterministic, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    354\u001b[0m                                deterministic=deterministic),\n\u001b[1;32m    355\u001b[0m         \u001b[0mmax_checkpoints_to_keep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         callbacks, all_losses)\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m   def fit_generator(self,\n",
      "\u001b[0;32m~/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;31m# Main training loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_training_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/models/graph_models.py\u001b[0m in \u001b[0;36mdefault_generator\u001b[0;34m(self, dataset, epochs, mode, deterministic, pad_batches)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m           \u001b[0mn_atoms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_atoms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m           \u001b[0;31m# number of atoms in each molecule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m           \u001b[0matom_split\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_atoms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'get_num_atoms'"
     ]
    }
   ],
   "source": [
    "model_MPNN.fit(train_dataset, nb_epoch=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression Model = 8개\n",
    "\n",
    "* 성공(3) = RandomForest, MultitaskNetwork(MultitaskRegressor), BypassNetwork(RobustMultitaskRegressor)\n",
    "* 실패(5) : DeepTensorNeuralNetworks(DTNNModel), GraphConvolutionalModel(GraphConvModel), DirectAcyclicGraphModel(DAGModel), WeaveModel, MessagePassingNeuralNetwork(MPNNModel)\n",
    "\n",
    "* 보통 data 형식이 안맞거나 parameter 설정(지식 부족)으로 error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "606server_virtual_env_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
