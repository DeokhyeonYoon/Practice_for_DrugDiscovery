{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict binding affinity from a protein-ligand crystal structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages installed in my conda environment: Deepchem, rdkit, pytorch, pytorch-geometric, tensorflow, pdbfixer, numpy <1.25\n",
    "# Deep Learning for the Life Sciences by Bharath Ramsundar, Peter Eastman, Patrick Walters and Vijay Pande\n",
    "# pdbbind dataset: Cheng, T.J. et al. J. Chem. Inf. Model., 2009, 49, 1079-1093. (PDBbind v.2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement transformaers (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for transformaers\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting tokenizers\n",
      "  Downloading tokenizers-0.15.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface_hub<1.0,>=0.16.4\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.42.1 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (22.0)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.4.0)\n",
      "Requirement already satisfied: requests in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.28.1)\n",
      "Requirement already satisfied: filelock in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.9.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from importlib-metadata->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.11.17)\n",
      "Installing collected packages: fsspec, huggingface_hub, tokenizers\n",
      "Successfully installed fsspec-2023.1.0 huggingface_hub-0.16.4 tokenizers-0.15.0\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting smart-open>=1.8.1\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from gensim) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from gensim) (1.21.5)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.2.0 smart-open-6.4.0\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement matminery (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for matminery\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting pyGPGO\n",
      "  Downloading pyGPGO-0.5.1.tar.gz (14 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from pyGPGO) (1.21.5)\n",
      "Collecting mkl\n",
      "  Downloading mkl-2024.0.0-py2.py3-none-manylinux1_x86_64.whl (200.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.7/200.7 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from pyGPGO) (1.7.3)\n",
      "Requirement already satisfied: joblib in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from pyGPGO) (1.1.1)\n",
      "Requirement already satisfied: scikit-learn in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from pyGPGO) (1.0.2)\n",
      "Collecting Theano-PyMC\n",
      "  Downloading Theano-PyMC-1.1.2.tar.gz (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyMC3\n",
      "  Downloading pymc3-3.11.5-py3-none-any.whl (872 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m872.2/872.2 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tbb==2021.*\n",
      "  Downloading tbb-2021.11.0-py2.py3-none-manylinux1_x86_64.whl (5.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting intel-openmp==2024.*\n",
      "  Downloading intel_openmp-2024.0.2-py2.py3-none-manylinux1_x86_64.whl (28.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.6/28.6 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting dill\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cachetools>=4.2.1 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from pyMC3->pyGPGO) (4.2.2)\n",
      "Collecting deprecat\n",
      "  Downloading deprecat-2.1.1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting semver>=2.13.0\n",
      "  Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
      "Collecting fastprogress>=0.2.0\n",
      "  Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from pyMC3->pyGPGO) (1.3.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from pyMC3->pyGPGO) (4.4.0)\n",
      "Collecting patsy>=0.5.1\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.9/233.9 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting arviz>=0.11.0\n",
      "  Downloading arviz-0.12.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from Theano-PyMC->pyGPGO) (3.9.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from scikit-learn->pyGPGO) (2.2.0)\n",
      "Collecting xarray>=0.16.1\n",
      "  Downloading xarray-0.20.2-py3-none-any.whl (845 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m845.2/845.2 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.0 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (3.5.3)\n",
      "Requirement already satisfied: packaging in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (22.0)\n",
      "Requirement already satisfied: setuptools>=38.4 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (65.6.3)\n",
      "Requirement already satisfied: netcdf4 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (1.6.2)\n",
      "Collecting xarray-einstats>=0.2\n",
      "  Downloading xarray_einstats-0.2.2-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from pandas>=0.24.0->pyMC3->pyGPGO) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from pandas>=0.24.0->pyMC3->pyGPGO) (2022.7)\n",
      "Requirement already satisfied: six in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from patsy>=0.5.1->pyMC3->pyGPGO) (1.16.0)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Downloading wrapt-1.16.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (9.4.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (4.11.3)\n",
      "Requirement already satisfied: cftime in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from netcdf4->arviz>=0.11.0->pyMC3->pyGPGO) (1.5.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from importlib-metadata->xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (3.11.0)\n",
      "Building wheels for collected packages: pyGPGO, Theano-PyMC\n",
      "  Building wheel for pyGPGO (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyGPGO: filename=pyGPGO-0.5.1-py3-none-any.whl size=19862 sha256=1d6741c4515862644089ebbe1f805c7690842e21108e6e542aa34435787e9d57\n",
      "  Stored in directory: /home/dbsejrgus226/.cache/pip/wheels/91/a9/7a/71f0635270b1a6dfb092d957e9e56eed6a8550116fa3027002\n",
      "  Building wheel for Theano-PyMC (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Theano-PyMC: filename=Theano_PyMC-1.1.2-py3-none-any.whl size=1529962 sha256=1f6edb214a42e601ee316742bed7efad2c5d5ca17eeb6f00298f48ff179530c6\n",
      "  Stored in directory: /home/dbsejrgus226/.cache/pip/wheels/ca/26/ff/1bccbd2d06d0ff14db22634e639715c0d7aadbc0c340060202\n",
      "Successfully built pyGPGO Theano-PyMC\n",
      "Installing collected packages: tbb, intel-openmp, wrapt, semver, patsy, mkl, fastprogress, dill, Theano-PyMC, deprecat, xarray, xarray-einstats, arviz, pyMC3, pyGPGO\n",
      "Successfully installed Theano-PyMC-1.1.2 arviz-0.12.1 deprecat-2.1.1 dill-0.3.7 fastprogress-1.0.3 intel-openmp-2024.0.2 mkl-2024.0.0 patsy-0.5.6 pyGPGO-0.5.1 pyMC3-3.11.5 semver-3.0.2 tbb-2021.11.0 wrapt-1.16.0 xarray-0.20.2 xarray-einstats-0.2.2\n"
     ]
    }
   ],
   "source": [
    "! pip install tokenizers\n",
    "! pip install gensim\n",
    "! pip install matminery\n",
    "! pip install pyGPGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: filelock in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from transformers) (4.11.3)\n",
      "Requirement already satisfied: requests in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from transformers) (4.64.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from transformers) (1.21.5)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.12.25-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (761 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m761.6/761.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.4.0)\n",
      "Requirement already satisfied: fsspec in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from requests->transformers) (2023.11.17)\n",
      "Installing collected packages: tokenizers, safetensors, regex, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.0\n",
      "    Uninstalling tokenizers-0.15.0:\n",
      "      Successfully uninstalled tokenizers-0.15.0\n",
      "Successfully installed regex-2023.12.25 safetensors-0.4.1 tokenizers-0.13.3 transformers-4.30.2\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement hsuite (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for hsuite\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: vina in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (1.2.5)\n",
      "Requirement already satisfied: numpy>=1.18 in /home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages (from vina) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "! pip install hsuite\n",
    "! pip install vina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to install Libraries in yml file\n",
    "1.\n",
    " - 일반적으로 yml/yaml file에 있는 라이브러리들은 `requirements.txt` 파일 형식으로 작성되어 있다.\n",
    " - `pip` 는 이 파일을 읽어 필요한 라이브러리를 한번에 설치할 수 있다.\n",
    "\n",
    "\n",
    " - `pip install -r requirements.txt` 이 명령은 `requirements.txt` 파일에 있는 각 라이브러리와 해당 버전을 자동으로 가져와 설치한다.\n",
    " * `requirements.txt` 파일이 있는 디렉토리로 이동한 후 명령을 실행해야 한다.\n",
    "2. yml/yaml 파일을 사용하여 conda 환경 생성\n",
    " - `conda env create -f file_name.yml`\n",
    " - `conda activate env_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "import openmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = dc.feat.RdkitGridFeaturizer(voxel_width=2.0,\n",
    "                                         feature_types=[\"ecfp\", \"splif\", \"salt_bridge\", \"hbond\"],\n",
    "                                         flatten = True,\n",
    "                                         sanitize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/utils/geometry_utils.py:22: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return vector / np.linalg.norm(vector)\n"
     ]
    }
   ],
   "source": [
    "tasks, datasets, transformers = dc.molnet.load_pdbbind(featurizer=featurizer, reload=False, set_name = \"core\", data_dir=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-logKd/Ki']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<deepchem.trans.transformers.NormalizationTransformer at 0x7f5af999aed0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, vaild, test = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int8\n",
      "float64\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(train.X.dtype)\n",
    "print(train.y.dtype)\n",
    "print(train.w.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.X.astype(\"float32\")\n",
    "y_train = train.y.astype(\"float32\")\n",
    "w_train = train.w.astype(\"float32\")\n",
    "\n",
    "x_test = test.X.astype(\"float32\")\n",
    "y_test = test.y.astype(\"float32\")\n",
    "w_test = test.w.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 18432)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dc.data.NumpyDataset(x_train, y_train, w_train)\n",
    "test_dataset = dc.data.NumpyDataset(x_test, y_test, w_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 18432)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'KerasModel' from 'deepchem.models' (/home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/models/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_59570/594055310.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDTNNModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/models/graph_models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmol_graphs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvMol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_one_hot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mL2Loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSoftmaxCrossEntropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrans\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mundo_transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'KerasModel' from 'deepchem.models' (/home/dbsejrgus226/miniconda3/envs/deepchem/lib/python3.7/site-packages/deepchem/models/__init__.py)"
     ]
    }
   ],
   "source": [
    "from deepchem.models.graph_models import DTNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DTNNModel(n_tasks=1,\n",
    "                  n_embedding=20,\n",
    "                  n_distance=100,\n",
    "                  learning_rate=1.0,\n",
    "                  mode=\"regression\",\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qsar/lib/python3.8/site-packages/deepchem/models/keras_model.py:351\u001b[0m, in \u001b[0;36mKerasModel.fit\u001b[0;34m(self, dataset, nb_epoch, max_checkpoints_to_keep, checkpoint_interval, deterministic, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    303\u001b[0m         dataset: Dataset,\n\u001b[1;32m    304\u001b[0m         nb_epoch: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    311\u001b[0m         callbacks: Union[Callable, List[Callable]] \u001b[38;5;241m=\u001b[39m [],\n\u001b[1;32m    312\u001b[0m         all_losses: Optional[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    313\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Train this model on a dataset.\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m  Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m  The average loss over the most recent checkpoint interval\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;124;03m \"\"\"\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_checkpoints_to_keep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_losses\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qsar/lib/python3.8/site-packages/deepchem/models/keras_model.py:429\u001b[0m, in \u001b[0;36mKerasModel.fit_generator\u001b[0;34m(self, generator, max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    425\u001b[0m time1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# Main training loop.\u001b[39;00m\n\u001b[0;32m--> 429\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m generator:\n\u001b[1;32m    430\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_training_ops(batch)\n\u001b[1;32m    431\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m restore:\n",
      "File \u001b[0;32m~/miniconda3/envs/qsar/lib/python3.8/site-packages/deepchem/models/graph_models.py:565\u001b[0m, in \u001b[0;36mDTNNModel.default_generator\u001b[0;34m(self, dataset, epochs, mode, deterministic, pad_batches)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m (X_b, y_b, w_b,\n\u001b[1;32m    562\u001b[0m        ids_b) \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39miterbatches(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m    563\u001b[0m                                      deterministic\u001b[38;5;241m=\u001b[39mdeterministic,\n\u001b[1;32m    564\u001b[0m                                      pad_batches\u001b[38;5;241m=\u001b[39mpad_batches):\n\u001b[0;32m--> 565\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_features_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_b\u001b[49m\u001b[43m)\u001b[49m, [y_b], [w_b])\n",
      "File \u001b[0;32m~/miniconda3/envs/qsar/lib/python3.8/site-packages/deepchem/models/graph_models.py:521\u001b[0m, in \u001b[0;36mDTNNModel.compute_features_on_batch\u001b[0;34m(self, X_b)\u001b[0m\n\u001b[1;32m    519\u001b[0m distance_membership_i \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    520\u001b[0m distance_membership_j \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 521\u001b[0m num_atoms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28msum\u001b[39m, \u001b[43mX_b\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[1;32m    522\u001b[0m atom_number \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    523\u001b[0m     np\u001b[38;5;241m.\u001b[39mround(\n\u001b[1;32m    524\u001b[0m         np\u001b[38;5;241m.\u001b[39mpower(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mdiag(X_b[i, :num_atoms[i], :num_atoms[i]]),\n\u001b[1;32m    525\u001b[0m                  \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.4\u001b[39m))\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(num_atoms))\n\u001b[1;32m    526\u001b[0m ]\n\u001b[1;32m    527\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, nb_epoch=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = model.evaluate(train_dataset, [metric], transformers)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = model.evaluate(test_dataset, [metric], transformers)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_on_batch(test_dataset.X)\n",
    "prediction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = prediction.reshape(20)\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax = sns.scatterplot(x=test_dataset.y, y=prediction)\n",
    "ax.set_title('pdbbind dataset')\n",
    "ax.set_xlabel('True')\n",
    "ax.set_ylabel('prediction')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "606server_virtual_env_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
